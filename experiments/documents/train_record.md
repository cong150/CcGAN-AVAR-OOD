(p312) wxc@V100-32Gx4-S2:~/nuist-lab/CcGAN-AVAR-OOD$ ./experiments/step1_train_aux_regression.sh
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘      æ­¥éª¤1ï¼šè®­ç»ƒè¾…åŠ©å›žå½’æ¨¡åž‹ï¼ˆResNet18ï¼‰                  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

é…ç½®ä¿¡æ¯ï¼š
  é¡¹ç›®è·¯å¾„: /home/wxc/nuist-lab/CcGAN-AVAR-OOD
  æ•°æ®è·¯å¾„: /home/wxc/datasets
  è®­ç»ƒèŒƒå›´: 0-90åº¦ï¼ˆå…¨èŒƒå›´ï¼‰
  è®­ç»ƒè½®æ•°: 200 epochs


===================================================================================================

 Loaded entire RC-49 dataset: 176400x3x64x64

 The original training set contains 22050 images with labels in [0.0,90.0]; for each label, select no more than 1048576 images.>>>
 22050 images left and there are 450 unique labels

 The training set's dimension: 22050x3x64x64
 Range of unnormalized labels: (0.1,89.9)
 Range of normalized labels: (0.0011111111111111111,0.9988888888888889)
/home/wxc/nuist-lab/CcGAN-AVAR-OOD/output/RC-49_64/aux_reg_model/ckpt_resnet18_epoch_200.pth

 Begin training CNN: 
PreAuxReg resnet18: [epoch 1/200] train_loss:0.015981 Time:4.8293

....

PreAuxReg resnet18: [epoch 200/200] train_loss:0.000120 Time:858.1878
Time elapses: 858.1879318528809s

===================================================================================================

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    âœ“ æ­¥éª¤1å®Œæˆï¼                          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

æ£€æŸ¥ç‚¹ä¿å­˜åœ¨:
  /home/wxc/nuist-lab/CcGAN-AVAR-OOD/output/RC-49_64/aux_reg_model/ckpt_resnet18_epoch_200.pth

ä¸‹ä¸€æ­¥ï¼šæ‰§è¡Œæ­¥éª¤2ï¼Œå‡†å¤‡æ··åˆæ•°æ®é›†
  bash step2_prepare_data.sh

(p312) wxc@V100-32Gx4-S2:~/nuist-lab/CcGAN-AVAR-OOD$ ./experiments/step2_prepare_data.sh
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           æ­¥éª¤2ï¼šå‡†å¤‡æ··åˆè®­ç»ƒæ•°æ®ï¼ˆå¯é€‰ï¼‰                 â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

åˆ›å»ºæ··åˆè®­ç»ƒé›†ï¼ˆ0-45åº¦å…¨éƒ¨ + 45-90åº¦æ¯è§’åº¦50å¼ ï¼‰...

================================================================================
åˆ›å»ºæ··åˆè®­ç»ƒé›†:
  IDåŒºåŸŸ (å…¨éƒ¨æ•°æ®): [0.0, 45.0]

  OODåŒºåŸŸ (å°‘é‡æ•°æ®): [45.0, 90.0], æ¯æ ‡ç­¾5å¼ 

åŠ è½½å®Œæ•´æ•°æ®é›†: (176400, 3, 64, 64)
âœ“ IDåŒºåŸŸ [0.0, 45.0]: 11025 å¼ ï¼ˆå…¨éƒ¨ï¼‰
âœ“ OODåŒºåŸŸ [45.0, 90.0]: 1125 å¼ ï¼ˆé‡‡æ ·åŽï¼‰

âœ“ æ··åˆè®­ç»ƒé›†æ€»è®¡: 12150 å¼ 

  - ID: 11025 å¼ 
  - OOD: 1125 å¼ 

âœ“ ä¿å­˜åˆ°: experiments/data/RC-49_mixed_id_full_ood_50_64x64.h5


â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    âœ“ æ­¥éª¤2å®Œæˆï¼                          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ç”Ÿæˆçš„æ–‡ä»¶ï¼š
  experiments/data/RC-49_mixed_id_full_ood_50_64x64.h5

æ•°æ®é›†è¯´æ˜Žï¼š

  - IDåŒºåŸŸï¼ˆ0-45åº¦ï¼‰ï¼šå…¨éƒ¨è®­ç»ƒæ•°æ®ï¼ˆçº¦10000å¼ ï¼‰
  - OODåŒºåŸŸï¼ˆ45-90åº¦ï¼‰ï¼šæ¯ä¸ªè§’åº¦50å¼ ï¼ˆçº¦2250å¼ ï¼‰
  - è¿™ä¸ªæ··åˆæ•°æ®é›†ç”¨äºŽæ­¥éª¤4çš„Simple-Mixå®žéªŒ

å®žéªŒè®¾è®¡ï¼š
  Step 3: Baselineï¼ˆåªç”¨0-45åº¦ï¼‰â†’ éªŒè¯OODé—®é¢˜
  Step 4: Simple-Mixï¼ˆæ··åˆæ•°æ®ï¼‰â†’ æµ‹è¯•ç®€å•æ–¹æ³•
  Step 5: Oracleï¼ˆå…¨éƒ¨æ•°æ®ï¼‰â†’ æ€§èƒ½ä¸Šç•Œ

ä¸‹ä¸€æ­¥ï¼šæ‰§è¡Œæ­¥éª¤3ï¼Œè®­ç»ƒBaselineæ¨¡åž‹
  bash experiments/step3_baseline_id_only.sh

(p312) wxc@V100-32Gx4-S2:~/nuist-lab/CcGAN-AVAR-OOD$ ./experiments/step3_baseline_id_only.sh
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘      æ­¥éª¤3ï¼šè®­ç»ƒBaselineï¼ˆåªç”¨0-45åº¦ï¼‰                    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


===================================================================================================

 Loaded entire RC-49 dataset: 176400x3x64x64

 The original training set contains 11025 images with labels in [0.0,45.0]; for each label, select no more than 1048576 images.>>>
 11025 images left and there are 225 unique labels

 The training set's dimension: 11025x3x64x64
 Range of unnormalized labels: (0.1,44.9)
 Range of normalized labels: (0.0022222222222222222,0.9977777777777778)

 The evaluation set's dimension: 22001x3x64x64

 Use rule-of-thumb formula to compute kernel_sigma >>>
 The std of 11025 labels is 0.2887 so the kernel sigma is 0.0476
 Kappa:12656.2500

 Loaded entire RC-49 dataset: 176400x3x64x64

 The original training set contains 11025 images with labels in [0.0,45.0]; for each label, select no more than 1048576 images.>>>
 11025 images left and there are 225 unique labels

 The training set's dimension: 11025x3x64x64
 Range of unnormalized labels: (0.1,44.9)
 Range of normalized labels: (0.0022222222222222222,0.9977777777777778)

 Start training CNN for y2h label embedding >>>
Train resnet_y2h for embedding: [epoch 1/10] train_loss:0.1233 Time:8.1523
Train resnet_y2h for embedding: [epoch 2/10] train_loss:0.0553 Time:15.9871
Train resnet_y2h for embedding: [epoch 3/10] train_loss:0.0419 Time:23.7749
Train resnet_y2h for embedding: [epoch 4/10] train_loss:0.0326 Time:31.6060
Train resnet_y2h for embedding: [epoch 5/10] train_loss:0.0273 Time:39.4846
Train resnet_y2h for embedding: [epoch 6/10] train_loss:0.0223 Time:47.2775
Train resnet_y2h for embedding: [epoch 7/10] train_loss:0.0202 Time:55.1069
Train resnet_y2h for embedding: [epoch 8/10] train_loss:0.0182 Time:62.9678
Train resnet_y2h for embedding: [epoch 9/10] train_loss:0.0168 Time:70.8641
Train resnet_y2h for embedding: [epoch 10/10] train_loss:0.0147 Time:78.6887

 Start training mlp_y2h >>>

 Train mlp_y2h: [epoch 1/500] train_loss:0.1969 Time:0.0140

...

 Train mlp_y2h: [epoch 500/500] train_loss:0.0000 Time:4.3469

 labels vs reconstructed labels
[[0.9311111  0.93788785]
 [0.5977778  0.5955275 ]
 [0.5222222  0.5226192 ]
 [0.7311111  0.73126745]
 [0.25111112 0.25215036]
 [0.85555553 0.8583613 ]
 [0.43333334 0.4332686 ]
 [0.19777778 0.19719467]
 [0.55333334 0.55224305]
 [0.9444444  0.9499007 ]]

 noisy labels vs reconstructed labels
[[0.76645756 0.7662793 ]
 [0.5018307  0.501758  ]
 [0.382563   0.38327265]
 [0.51762563 0.5181409 ]
 [0.26714763 0.26782677]
 [0.86889595 0.87274843]
 [0.5229748  0.523339  ]
 [0.09852201 0.09643986]
 [0.59032255 0.587784  ]
 [0.7674459  0.76728886]]
 netG size: {'Total': 20301571, 'Trainable': 20301571}
 netD size: {'Total': 20642579, 'Trainable': 20642579}

 Training labels' range is [0.0022222222222222222,0.9977777777777778].
[0.05111111 0.05111111 0.05111111 0.05111111 0.05111111 0.05111111
 0.05111111 0.05111111 0.05111111 0.05111111 0.1508642  0.1508642
 0.1508642  0.1508642  0.1508642  0.1508642  0.1508642  0.1508642
 0.1508642  0.1508642  0.25061728 0.25061728 0.25061728 0.25061728
 0.25061728 0.25061728 0.25061728 0.25061728 0.25061728 0.25061728
 0.35037037 0.35037037 0.35037037 0.35037037 0.35037037 0.35037037
 0.35037037 0.35037037 0.35037037 0.35037037 0.45012346 0.45012346
 0.45012346 0.45012346 0.45012346 0.45012346 0.45012346 0.45012346
 0.45012346 0.45012346 0.54987654 0.54987654 0.54987654 0.54987654
 0.54987654 0.54987654 0.54987654 0.54987654 0.54987654 0.54987654
 0.64962963 0.64962963 0.64962963 0.64962963 0.64962963 0.64962963
 0.64962963 0.64962963 0.64962963 0.64962963 0.74938272 0.74938272
 0.74938272 0.74938272 0.74938272 0.74938272 0.74938272 0.74938272
 0.74938272 0.74938272 0.8491358  0.8491358  0.8491358  0.8491358
 0.8491358  0.8491358  0.8491358  0.8491358  0.8491358  0.8491358
 0.94888889 0.94888889 0.94888889 0.94888889 0.94888889 0.94888889
 0.94888889 0.94888889 0.94888889 0.94888889]


Begin Training:

 CcGAN,SNGAN,hinge: [Iter 20/30000] [D loss: 0.578/0.308/-1.381] [G loss: 0.942/0.233/0.003] [Time: 18.969]

==è§£é‡Š==ï¼šCcGAN â‰  ä¸€ä¸ªæ¨¡åž‹æž¶æž„

CcGANæ˜¯ä¸€ä¸ªè®­ç»ƒæ¡†æž¶/æ–¹æ³•ï¼Œä¸æ˜¯ç‹¬ç«‹çš„GANæž¶æž„ï¼

```
CcGAN = è®­ç»ƒæ¡†æž¶ (Training Framework)
   â”œâ”€â”€ æ ¸å¿ƒæ€æƒ³ï¼šVicinal Loss (é‚»åŸŸæŸå¤±)
   â”œâ”€â”€ Label Embedding (æ ‡ç­¾åµŒå…¥)
   â””â”€â”€ å¯ä»¥ç”¨åœ¨ä»»ä½•GANæž¶æž„ä¸Š
       â”œâ”€â”€ SNGAN (Spectral Normalization GAN)
       â”œâ”€â”€ SAGAN (Self-Attention GAN)  
       â”œâ”€â”€ BigGAN
       â”œâ”€â”€ BigGAN-Deep
       â””â”€â”€ DCGAN
```

ç±»æ¯”ç†è§£

```
CcGAN = è®­ç»ƒæ¡†æž¶ (Training Framework)
   â”œâ”€â”€ æ ¸å¿ƒæ€æƒ³ï¼šVicinal Loss (é‚»åŸŸæŸå¤±)
   â”œâ”€â”€ Label Embedding (æ ‡ç­¾åµŒå…¥)
   â””â”€â”€ å¯ä»¥ç”¨åœ¨ä»»ä½•GANæž¶æž„ä¸Š
       â”œâ”€â”€ SNGAN (Spectral Normalization GAN)
       â”œâ”€â”€ SAGAN (Self-Attention GAN)  
       â”œâ”€â”€ BigGAN
       â”œâ”€â”€ BigGAN-Deep
       â””â”€â”€ DCGAN
```

ä»£ç ä¸­çš„ä½“çŽ°

çœ‹ï¼CcGANçš„æ ¸å¿ƒé€»è¾‘åœ¨trainer.pyä¸­ï¼Œä¸åœ¨modelsé‡Œï¼

#### å®Œæ•´çš„å…³ç³»å›¾

```
# å®Œæ•´çš„CcGAN-AVARç³»ç»Ÿï¼š

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CcGAN-AVAR Training Framework (trainer.py) â”‚
â”‚  â”œâ”€â”€ Vicinal Loss (é‚»åŸŸæŸå¤±)                 â”‚
â”‚  â”œâ”€â”€ Adaptive Vicinity (è‡ªé€‚åº”é‚»åŸŸ) â†AVARæ ¸å¿ƒâ”‚
â”‚  â”œâ”€â”€ Label Embedding (æ ‡ç­¾åµŒå…¥)              â”‚
â”‚  â”œâ”€â”€ Auxiliary Regression (è¾…åŠ©å›žå½’)         â”‚
â”‚  â””â”€â”€ DRE Regularization (å¯†åº¦æ¯”ä¼°è®¡)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“ åº”ç”¨åœ¨
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GANæž¶æž„ (models/)                           â”‚
â”‚  â”œâ”€â”€ SNGAN â† é»˜è®¤é€‰æ‹©(ç¨³å®šé«˜æ•ˆ) âœ…            â”‚
â”‚  â”œâ”€â”€ SAGAN (æœ‰self-attention)               â”‚
â”‚  â”œâ”€â”€ BigGAN (å¤§æ¨¡åž‹)                         â”‚
â”‚  â”œâ”€â”€ BigGAN-Deep (æ›´æ·±çš„æ¨¡åž‹)                â”‚
â”‚  â””â”€â”€ DCGAN (ç®€å•åŸºçº¿)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### ä¸ºä»€ä¹ˆé€‰SNGANï¼Ÿ

1. ç¨³å®šæ€§å¥½ï¼šSpectral Normalizationè®©è®­ç»ƒæ›´ç¨³å®š

1. æ•ˆçŽ‡é«˜ï¼šæ¯”BigGANè½»é‡ï¼Œæ¯”DCGANå¼º

1. æ•ˆæžœå¥½ï¼š64x64å›¾åƒè¶³å¤Ÿäº†

1. è®ºæ–‡å¸¸ç”¨ï¼šCcGANåŽŸå§‹è®ºæ–‡å°±ç”¨SNGAN

#### å…¶ä»–æ¨¡åž‹å¯ä»¥ç”¨å—ï¼Ÿ

å½“ç„¶å¯ä»¥ï¼ ä¿®æ”¹é…ç½®å³å¯ï¼š

```
# ä½¿ç”¨SAGAN
NET_NAME="SAGAN"

# ä½¿ç”¨BigGAN  
NET_NAME="BigGAN"
--use_sn --use_attn

# ä½¿ç”¨DCGAN
NET_NAME="DCGAN"
```



...

 CcGAN,SNGAN,hinge: [Iter 29940/30000] [D loss: 1.088/0.235/-1.405] [G loss: 0.858/0.171/0.036] [Time: 8522.196]

 CcGAN,SNGAN,hinge: [Iter 29960/30000] [D loss: 1.188/0.226/-1.377] [G loss: 0.621/0.131/0.000] [Time: 8539.240]

 CcGAN,SNGAN,hinge: [Iter 29980/30000] [D loss: 1.090/0.205/-1.424] [G loss: 0.746/0.180/0.032] [Time: 8556.278]

 CcGAN,SNGAN,hinge: [Iter 30000/30000] [D loss: 1.130/0.227/-1.387] [G loss: 0.758/0.144/0.009] [Time: 8573.313]
training complete 

End training; Time elapses: 8574.150417611934s. 


 Start sampling fake images from the model >>>

 ====================================================================================
 Start evaluation...

 The evaluation set's dimension: 22001x3x64x64
[ 0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  1.   1.1  1.2  1.3  1.4
  1.5  1.6  1.7  1.8  1.9  2.   2.1  2.2  2.3  2.4  2.5  2.6  2.7  2.8
  2.9  3.   3.1  3.2  3.3  3.4  3.5  3.6  3.7  3.8  3.9  4.   4.1  4.2
  4.3  4.4  4.5  4.6  4.7  4.8  4.9  5.   5.1  5.2  5.3  5.4  5.5  5.6
  5.7  5.8  5.9  6.   6.1  6.2  6.3  6.4  6.5  6.6  6.7  6.8  6.9  7.
  7.1  7.2  7.3  7.4  7.5  7.6  7.7  7.8  7.9  8.   8.1  8.2  8.3  8.4
  8.5  8.6  8.7  8.8  8.9  9.   9.1  9.2  9.3  9.4  9.5  9.6  9.7  9.8
  9.9 10.  10.1 10.2 10.3 10.4 10.5 10.6 10.7 10.8 10.9 11.  11.1 11.2
 11.3 11.4 11.5 11.6 11.7 11.8 11.9 12.  12.1 12.2 12.3 12.4 12.5 12.6
 12.7 12.8 12.9 13.  13.1 13.2 13.3 13.4 13.5 13.6 13.7 13.8 13.9 14.
 14.1 14.2 14.3 14.4 14.5 14.6 14.7 14.8 14.9 15.  15.1 15.2 15.3 15.4
 15.5 15.6 15.7 15.8 15.9 16.  16.1 16.2 16.3 16.4 16.5 16.6 16.7 16.8
 16.9 17.  17.1 17.2 17.3 17.4 17.5 17.6 17.7 17.8 17.9 18.  18.1 18.2
 18.3 18.4 18.5 18.6 18.7 18.8 18.9 19.  19.1 19.2 19.3 19.4 19.5 19.6
 19.7 19.8 19.9 20.  20.1 20.2 20.3 20.4 20.5 20.6 20.7 20.8 20.9 21.
 21.1 21.2 21.3 21.4 21.5 21.6 21.7 21.8 21.9 22.  22.1 22.2 22.3 22.4
 22.5 22.6 22.7 22.8 22.9 23.  23.1 23.2 23.3 23.4 23.5 23.6 23.7 23.8
 23.9 24.  24.1 24.2 24.3 24.4 24.5 24.6 24.7 24.8 24.9 25.  25.1 25.2
 25.3 25.4 25.5 25.6 25.7 25.8 25.9 26.  26.1 26.2 26.3 26.4 26.5 26.6
 26.7 26.8 26.9 27.  27.1 27.2 27.3 27.4 27.5 27.6 27.7 27.8 27.9 28.
 28.1 28.2 28.3 28.4 28.5 28.6 28.7 28.8 28.9 29.  29.1 29.2 29.3 29.4
 29.5 29.6 29.7 29.8 29.9 30.  30.1 30.2 30.3 30.4 30.5 30.6 30.7 30.8
 30.9 31.  31.1 31.2 31.3 31.4 31.5 31.6 31.7 31.8 31.9 32.  32.1 32.2
 32.3 32.4 32.5 32.6 32.7 32.8 32.9 33.  33.1 33.2 33.3 33.4 33.5 33.6
 33.7 33.8 33.9 34.  34.1 34.2 34.3 34.4 34.5 34.6 34.7 34.8 34.9 35.
 35.1 35.2 35.3 35.4 35.5 35.6 35.7 35.8 35.9 36.  36.1 36.2 36.3 36.4
 36.5 36.6 36.7 36.8 36.9 37.  37.1 37.2 37.3 37.4 37.5 37.6 37.7 37.8
 37.9 38.  38.1 38.2 38.3 38.4 38.5 38.6 38.7 38.8 38.9 39.  39.1 39.2
 39.3 39.4 39.5 39.6 39.7 39.8 39.9 40.  40.1 40.2 40.3 40.4 40.5 40.6
 40.7 40.8 40.9 41.  41.1 41.2 41.3 41.4 41.5 41.6 41.7 41.8 41.9 42.
 42.1 42.2 42.3 42.4 42.5 42.6 42.7 42.8 42.9 43.  43.1 43.2 43.3 43.4
 43.5 43.6 43.7 43.8 43.9 44.  44.1 44.2 44.3 44.4 44.5 44.6 44.7 44.8
 44.9]
0 45.0
Dataset: RC-49; Resolution: 64x64; num_classes: 49
./evaluation/eval_ckpts/RC49/metrics_64x64/ckpt_AE_epoch_200_seed_2020_CVMode_False.pth
./evaluation/eval_ckpts/RC49/metrics_64x64/ckpt_PreCNNForEvalGANs_ResNet34_class_epoch_200_seed_2020_classify_49_chair_types_CVMode_False.pth
./evaluation/eval_ckpts/RC49/metrics_64x64/ckpt_PreCNNForEvalGANs_ResNet34_regre_epoch_200_seed_2020_CVMode_False.pth

 Start generating fake image-label pairs for evaluation...
100% [##################################################]
 449/449: Got 89800 fake images. Time spent 33.76 sec.
 Fake images shape: (89800, 3, 64, 64)
from evaluation.eval_models.RC49.metrics_64x64 import ResNet34_class_eval, ResNet34_regre_eval, encoder

===================================================================================================

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    âœ“ æ­¥éª¤3å®Œæˆï¼                          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

æ¨¡åž‹ä¿å­˜åœ¨:
  /home/wxc/nuist-lab/CcGAN-AVAR-OOD/output/RC-49_64/baseline_id_only/

å®žéªŒè¯´æ˜Ž:
  è¿™ä¸ªå®žéªŒéªŒè¯'çº¯IDè®­ç»ƒ'åœ¨OODåŒºåŸŸçš„å¤±è´¥
  é¢„æœŸï¼š0-45åº¦ç”Ÿæˆå¥½ï¼Œ45-90åº¦ç”Ÿæˆå·®

ä¸‹ä¸€æ­¥ï¼šæ‰§è¡Œæ­¥éª¤4ï¼Œè®­ç»ƒSimple-Mixï¼ˆæµ‹è¯•ç®€å•æ··åˆï¼‰
  bash experiments/step4_simple_mix.sh

(p312) wxc@V100-32Gx4-S2:~/nuist-lab/CcGAN-AVAR-OOD$ ./experiments/step4_simple_mix.sh
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘    æ­¥éª¤4ï¼šè®­ç»ƒSimple-Mixï¼ˆç®€å•æ··åˆåŸºçº¿ï¼‰                  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

åˆ›å»ºæ•°æ®é›†ç¬¦å·é“¾æŽ¥...
/home/wxc/.conda/envs/p312/lib/python3.12/site-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1729647378361/work/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]

===================================================================================================

 Loaded entire RC-49 dataset: 12150x3x64x64

 The original training set contains 12150 images with labels in [0.0,90.0]; for each label, select no more than 25 images.>>>
 6750 images left and there are 450 unique labels

 The training set's dimension: 6750x3x64x64
 Range of unnormalized labels: (0.1,89.9)
 Range of normalized labels: (0.0011111111111111111,0.9988888888888889)

 The evaluation set's dimension: 12150x3x64x64

 Use rule-of-thumb formula to compute kernel_sigma >>>
 The std of 6750 labels is 0.2357 so the kernel sigma is 0.0428
 Kappa:50625.0000

 Loaded entire RC-49 dataset: 12150x3x64x64

 The original training set contains 12150 images with labels in [0.0,90.0]; for each label, select no more than 25 images.>>>
 6750 images left and there are 450 unique labels

 The training set's dimension: 6750x3x64x64
 Range of unnormalized labels: (0.1,89.9)
 Range of normalized labels: (0.0011111111111111111,0.9988888888888889)

 resnet_y2h ckpt already exists

 Loading...

 model mlp_y2h ckpt already exists

 Loading...

 labels vs reconstructed labels
[[0.84555554 0.84740907]
 [0.4077778  0.4070759 ]
 [0.56777775 0.56563437]
 [0.36333334 0.36433592]
 [0.87222224 0.8763129 ]
 [0.86333334 0.8667738 ]
 [0.91888887 0.9257793 ]
 [0.4188889  0.41846147]
 [0.09       0.08744127]
 [0.79888886 0.7986081 ]]

 noisy labels vs reconstructed labels
[[0.7223062  0.72291553]
 [0.5106903  0.5108215 ]
 [0.7399287  0.7394895 ]
 [0.16721189 0.16677207]
 [1.         0.9952517 ]
 [0.56360155 0.5618657 ]
 [1.         0.9952517 ]
 [0.53167486 0.53166276]
 [0.3506049  0.3516533 ]
 [0.7778506  0.7778376 ]]
 netG size: {'Total': 20301571, 'Trainable': 20301571}
 netD size: {'Total': 20642579, 'Trainable': 20642579}

 Training labels' range is [0.0011111111111111111,0.9988888888888889].
[0.03       0.03       0.03       0.03       0.03       0.03
 0.03       0.03       0.03       0.03       0.12111111 0.12111111
 0.12111111 0.12111111 0.12111111 0.12111111 0.12111111 0.12111111
 0.12111111 0.12111111 0.21222222 0.21222222 0.21222222 0.21222222
 0.21222222 0.21222222 0.21222222 0.21222222 0.21222222 0.21222222
 0.30333333 0.30333333 0.30333333 0.30333333 0.30333333 0.30333333
 0.30333333 0.30333333 0.30333333 0.30333333 0.39444444 0.39444444
 0.39444444 0.39444444 0.39444444 0.39444444 0.39444444 0.39444444
 0.39444444 0.39444444 0.48555556 0.48555556 0.48555556 0.48555556
 0.48555556 0.48555556 0.48555556 0.48555556 0.48555556 0.48555556
 0.57666667 0.57666667 0.57666667 0.57666667 0.57666667 0.57666667
 0.57666667 0.57666667 0.57666667 0.57666667 0.66777778 0.66777778
 0.66777778 0.66777778 0.66777778 0.66777778 0.66777778 0.66777778
 0.66777778 0.66777778 0.75888889 0.75888889 0.75888889 0.75888889
 0.75888889 0.75888889 0.75888889 0.75888889 0.75888889 0.75888889
 0.85       0.85       0.85       0.85       0.85       0.85
 0.85       0.85       0.85       0.85      ]


Begin Training:

 CcGAN,SNGAN,hinge: [Iter 20/30000] [D loss: 1.082/0.742/-1.335] [G loss: 0.047/0.494/0.027] [Time: 18.296]

 CcGAN,SNGAN,hinge: [Iter 40/30000] [D loss: 0.901/0.995/-1.369] [G loss: 0.501/0.518/0.088] [Time: 35.881]

 CcGAN,SNGAN,hinge: [Iter 60/30000] [D loss: 1.138/1.092/-1.340] [G loss: 1.278/0.498/0.643] [Time: 53.422]

 CcGAN,SNGAN,hinge: [Iter 80/30000] [D loss: 1.180/0.966/-1.311] [G loss: 0.776/0.487/0.000] [Time: 70.966]

...

 CcGAN,SNGAN,hinge: [Iter 29980/30000] [D loss: 1.132/0.964/-1.406] [G loss: 0.707/0.503/0.088] [Time: 26134.881]

 CcGAN,SNGAN,hinge: [Iter 30000/30000] [D loss: 0.981/1.022/-1.424] [G loss: 0.565/0.513/0.029] [Time: 26152.223]
training complete 

End training; Time elapses: 26153.075779294828s. 


 Start sampling fake images from the model >>>

 ====================================================================================
 Start evaluation...

 The evaluation set's dimension: 12150x3x64x64
[ 0.1  0.3  0.5  0.7  0.9  1.1  1.3  1.5  1.7  1.9  2.1  2.3  2.5  2.7
  2.9  3.1  3.3  3.5  3.7  3.9  4.1  4.3  4.5  4.7  4.9  5.1  5.3  5.5
  5.7  5.9  6.1  6.3  6.5  6.7  6.9  7.1  7.3  7.5  7.7  7.9  8.1  8.3
  8.5  8.7  8.9  9.1  9.3  9.5  9.7  9.9 10.1 10.3 10.5 10.7 10.9 11.1
 11.3 11.5 11.7 11.9 12.1 12.3 12.5 12.7 12.9 13.1 13.3 13.5 13.7 13.9
 14.1 14.3 14.5 14.7 14.9 15.1 15.3 15.5 15.7 15.9 16.1 16.3 16.5 16.7
 16.9 17.1 17.3 17.5 17.7 17.9 18.1 18.3 18.5 18.7 18.9 19.1 19.3 19.5
 19.7 19.9 20.1 20.3 20.5 20.7 20.9 21.1 21.3 21.5 21.7 21.9 22.1 22.3
 22.5 22.7 22.9 23.1 23.3 23.5 23.7 23.9 24.1 24.3 24.5 24.7 24.9 25.1
 25.3 25.5 25.7 25.9 26.1 26.3 26.5 26.7 26.9 27.1 27.3 27.5 27.7 27.9
 28.1 28.3 28.5 28.7 28.9 29.1 29.3 29.5 29.7 29.9 30.1 30.3 30.5 30.7
 30.9 31.1 31.3 31.5 31.7 31.9 32.1 32.3 32.5 32.7 32.9 33.1 33.3 33.5
 33.7 33.9 34.1 34.3 34.5 34.7 34.9 35.1 35.3 35.5 35.7 35.9 36.1 36.3
 36.5 36.7 36.9 37.1 37.3 37.5 37.7 37.9 38.1 38.3 38.5 38.7 38.9 39.1
 39.3 39.5 39.7 39.9 40.1 40.3 40.5 40.7 40.9 41.1 41.3 41.5 41.7 41.9
 42.1 42.3 42.5 42.7 42.9 43.1 43.3 43.5 43.7 43.9 44.1 44.3 44.5 44.7
 44.9 45.1 45.3 45.5 45.7 45.9 46.1 46.3 46.5 46.7 46.9 47.1 47.3 47.5
 47.7 47.9 48.1 48.3 48.5 48.7 48.9 49.1 49.3 49.5 49.7 49.9 50.1 50.3
 50.5 50.7 50.9 51.1 51.3 51.5 51.7 51.9 52.1 52.3 52.5 52.7 52.9 53.1
 53.3 53.5 53.7 53.9 54.1 54.3 54.5 54.7 54.9 55.1 55.3 55.5 55.7 55.9
 56.1 56.3 56.5 56.7 56.9 57.1 57.3 57.5 57.7 57.9 58.1 58.3 58.5 58.7
 58.9 59.1 59.3 59.5 59.7 59.9 60.1 60.3 60.5 60.7 60.9 61.1 61.3 61.5
 61.7 61.9 62.1 62.3 62.5 62.7 62.9 63.1 63.3 63.5 63.7 63.9 64.1 64.3
 64.5 64.7 64.9 65.1 65.3 65.5 65.7 65.9 66.1 66.3 66.5 66.7 66.9 67.1
 67.3 67.5 67.7 67.9 68.1 68.3 68.5 68.7 68.9 69.1 69.3 69.5 69.7 69.9
 70.1 70.3 70.5 70.7 70.9 71.1 71.3 71.5 71.7 71.9 72.1 72.3 72.5 72.7
 72.9 73.1 73.3 73.5 73.7 73.9 74.1 74.3 74.5 74.7 74.9 75.1 75.3 75.5
 75.7 75.9 76.1 76.3 76.5 76.7 76.9 77.1 77.3 77.5 77.7 77.9 78.1 78.3
 78.5 78.7 78.9 79.1 79.3 79.5 79.7 79.9 80.1 80.3 80.5 80.7 80.9 81.1
 81.3 81.5 81.7 81.9 82.1 82.3 82.5 82.7 82.9 83.1 83.3 83.5 83.7 83.9
 84.1 84.3 84.5 84.7 84.9 85.1 85.3 85.5 85.7 85.9 86.1 86.3 86.5 86.7
 86.9 87.1 87.3 87.5 87.7 87.9 88.1 88.3 88.5 88.7 88.9 89.1 89.3 89.5
 89.7 89.9]
0 90.0
Dataset: RC-49; Resolution: 64x64; num_classes: 49
./evaluation/eval_ckpts/RC49/metrics_64x64/ckpt_AE_epoch_200_seed_2020_CVMode_False.pth
./evaluation/eval_ckpts/RC49/metrics_64x64/ckpt_PreCNNForEvalGANs_ResNet34_class_epoch_200_seed_2020_classify_49_chair_types_CVMode_False.pth
./evaluation/eval_ckpts/RC49/metrics_64x64/ckpt_PreCNNForEvalGANs_ResNet34_regre_epoch_200_seed_2020_CVMode_False.pth

 Start generating fake image-label pairs for evaluation...
100% [##################################################]
 450/450: Got 90000 fake images. Time spent 33.78 sec.
 Fake images shape: (90000, 3, 64, 64)
from evaluation.eval_models.RC49.metrics_64x64 import ResNet34_class_eval, ResNet34_regre_eval, encoder

===================================================================================================

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    âœ“ æ­¥éª¤4å®Œæˆï¼                          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

æ¨¡åž‹ä¿å­˜åœ¨:
  /home/wxc/nuist-lab/CcGAN-AVAR-OOD/output/RC-49_64/simple_mix_50/

å®žéªŒè¯´æ˜Ž:
  è¿™ä¸ªå®žéªŒéªŒè¯'ç®€å•æ··åˆå°‘é‡OODæ•°æ®'çš„æ•ˆæžœ
  é¢„æœŸï¼šæ¯”Baselineæ”¹å–„ï¼Œä½†å¯èƒ½ä»ä¸å¤Ÿç†æƒ³

ä¸‹ä¸€æ­¥ï¼šæ‰§è¡Œæ­¥éª¤5ï¼Œè®­ç»ƒOracleï¼ˆæ€§èƒ½ä¸Šç•Œï¼‰
  bash experiments/step5_oracle_full.sh



(p312) wxc@V100-32Gx4-S2:~/nuist-lab/CcGAN-AVAR-OOD$ ./experiments/step5_oracle_full.sh
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘      æ­¥éª¤5ï¼šè®­ç»ƒOracleï¼ˆ0-90åº¦å…¨éƒ¨ï¼Œæ€§èƒ½ä¸Šç•Œï¼‰             â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

/home/wxc/.conda/envs/p312/lib/python3.12/site-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1729647378361/work/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]

===================================================================================================

 Loaded entire RC-49 dataset: 176400x3x64x64

 The original training set contains 22050 images with labels in [0.0,90.0]; for each label, select no more than 25 images.>>>
 11250 images left and there are 450 unique labels

 The training set's dimension: 11250x3x64x64
 Range of unnormalized labels: (0.1,89.9)
 Range of normalized labels: (0.0011111111111111111,0.9988888888888889)

 The evaluation set's dimension: 44051x3x64x64

 Use rule-of-thumb formula to compute kernel_sigma >>>
 The std of 11250 labels is 0.2887 so the kernel sigma is 0.0474
 Kappa:50625.0000

 Loaded entire RC-49 dataset: 176400x3x64x64

 The original training set contains 22050 images with labels in [0.0,90.0]; for each label, select no more than 25 images.>>>
 11250 images left and there are 450 unique labels

 The training set's dimension: 11250x3x64x64
 Range of unnormalized labels: (0.1,89.9)
 Range of normalized labels: (0.0011111111111111111,0.9988888888888889)

 resnet_y2h ckpt already exists

 Loading...

 model mlp_y2h ckpt already exists

 Loading...

 labels vs reconstructed labels
[[0.79       0.7897549 ]
 [0.52111113 0.52155715]
 [0.77       0.76989144]
 [0.7677778  0.76762754]
 [0.15444444 0.15469   ]
 [0.40333334 0.40254524]
 [0.5833333  0.5805443 ]
 [0.48777777 0.4877499 ]
 [0.76555556 0.76535684]
 [0.01       0.01026117]]

 noisy labels vs reconstructed labels
[[0.9653725  0.96731204]
 [0.3371601  0.3377464 ]
 [0.6918372  0.6929012 ]
 [0.28176254 0.28179052]
 [0.16196565 0.16164485]
 [0.6009065  0.59885854]
 [0.87246275 0.87657005]
 [0.10454318 0.10296389]
 [0.67049265 0.67181027]
 [0.         0.00122382]]
 netG size: {'Total': 20301571, 'Trainable': 20301571}
 netD size: {'Total': 20642579, 'Trainable': 20642579}

 Training labels' range is [0.0011111111111111111,0.9988888888888889].
[0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.15 0.15 0.15 0.15
 0.15 0.15 0.15 0.15 0.15 0.15 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25
 0.25 0.25 0.35 0.35 0.35 0.35 0.35 0.35 0.35 0.35 0.35 0.35 0.45 0.45
 0.45 0.45 0.45 0.45 0.45 0.45 0.45 0.45 0.55 0.55 0.55 0.55 0.55 0.55
 0.55 0.55 0.55 0.55 0.65 0.65 0.65 0.65 0.65 0.65 0.65 0.65 0.65 0.65
 0.75 0.75 0.75 0.75 0.75 0.75 0.75 0.75 0.75 0.75 0.85 0.85 0.85 0.85
 0.85 0.85 0.85 0.85 0.85 0.85 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95
 0.95 0.95]


Begin Training:

 CcGAN,SNGAN,hinge: [Iter 20/30000] [D loss: 0.980/0.890/-1.357] [G loss: 0.867/0.487/0.105] [Time: 19.306]

 CcGAN,SNGAN,hinge: [Iter 40/30000] [D loss: 0.880/0.889/-1.382] [G loss: 0.697/0.530/0.026] [Time: 37.911]

...

 CcGAN,SNGAN,hinge: [Iter 29980/30000] [D loss: 1.058/0.992/-1.415] [G loss: 0.611/0.484/0.037] [Time: 18708.279]

 CcGAN,SNGAN,hinge: [Iter 30000/30000] [D loss: 1.049/1.044/-1.430] [G loss: 0.764/0.483/0.089] [Time: 18726.999]
training complete 

End training; Time elapses: 18727.830003132112s. 


 Start sampling fake images from the model >>>

 ====================================================================================
 Start evaluation...

 The evaluation set's dimension: 44051x3x64x64
[ 0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  1.   1.1  1.2  1.3  1.4
  1.5  1.6  1.7  1.8  1.9  2.   2.1  2.2  2.3  2.4  2.5  2.6  2.7  2.8
  2.9  3.   3.1  3.2  3.3  3.4  3.5  3.6  3.7  3.8  3.9  4.   4.1  4.2
  4.3  4.4  4.5  4.6  4.7  4.8  4.9  5.   5.1  5.2  5.3  5.4  5.5  5.6
  5.7  5.8  5.9  6.   6.1  6.2  6.3  6.4  6.5  6.6  6.7  6.8  6.9  7.
  7.1  7.2  7.3  7.4  7.5  7.6  7.7  7.8  7.9  8.   8.1  8.2  8.3  8.4
  8.5  8.6  8.7  8.8  8.9  9.   9.1  9.2  9.3  9.4  9.5  9.6  9.7  9.8
  9.9 10.  10.1 10.2 10.3 10.4 10.5 10.6 10.7 10.8 10.9 11.  11.1 11.2
 11.3 11.4 11.5 11.6 11.7 11.8 11.9 12.  12.1 12.2 12.3 12.4 12.5 12.6
 12.7 12.8 12.9 13.  13.1 13.2 13.3 13.4 13.5 13.6 13.7 13.8 13.9 14.
 14.1 14.2 14.3 14.4 14.5 14.6 14.7 14.8 14.9 15.  15.1 15.2 15.3 15.4
 15.5 15.6 15.7 15.8 15.9 16.  16.1 16.2 16.3 16.4 16.5 16.6 16.7 16.8
 16.9 17.  17.1 17.2 17.3 17.4 17.5 17.6 17.7 17.8 17.9 18.  18.1 18.2
 18.3 18.4 18.5 18.6 18.7 18.8 18.9 19.  19.1 19.2 19.3 19.4 19.5 19.6
 19.7 19.8 19.9 20.  20.1 20.2 20.3 20.4 20.5 20.6 20.7 20.8 20.9 21.
 21.1 21.2 21.3 21.4 21.5 21.6 21.7 21.8 21.9 22.  22.1 22.2 22.3 22.4
 22.5 22.6 22.7 22.8 22.9 23.  23.1 23.2 23.3 23.4 23.5 23.6 23.7 23.8
 23.9 24.  24.1 24.2 24.3 24.4 24.5 24.6 24.7 24.8 24.9 25.  25.1 25.2
 25.3 25.4 25.5 25.6 25.7 25.8 25.9 26.  26.1 26.2 26.3 26.4 26.5 26.6
 26.7 26.8 26.9 27.  27.1 27.2 27.3 27.4 27.5 27.6 27.7 27.8 27.9 28.
 28.1 28.2 28.3 28.4 28.5 28.6 28.7 28.8 28.9 29.  29.1 29.2 29.3 29.4
 29.5 29.6 29.7 29.8 29.9 30.  30.1 30.2 30.3 30.4 30.5 30.6 30.7 30.8
 30.9 31.  31.1 31.2 31.3 31.4 31.5 31.6 31.7 31.8 31.9 32.  32.1 32.2
 32.3 32.4 32.5 32.6 32.7 32.8 32.9 33.  33.1 33.2 33.3 33.4 33.5 33.6
 33.7 33.8 33.9 34.  34.1 34.2 34.3 34.4 34.5 34.6 34.7 34.8 34.9 35.
 35.1 35.2 35.3 35.4 35.5 35.6 35.7 35.8 35.9 36.  36.1 36.2 36.3 36.4
 36.5 36.6 36.7 36.8 36.9 37.  37.1 37.2 37.3 37.4 37.5 37.6 37.7 37.8
 37.9 38.  38.1 38.2 38.3 38.4 38.5 38.6 38.7 38.8 38.9 39.  39.1 39.2
 39.3 39.4 39.5 39.6 39.7 39.8 39.9 40.  40.1 40.2 40.3 40.4 40.5 40.6
 40.7 40.8 40.9 41.  41.1 41.2 41.3 41.4 41.5 41.6 41.7 41.8 41.9 42.
 42.1 42.2 42.3 42.4 42.5 42.6 42.7 42.8 42.9 43.  43.1 43.2 43.3 43.4
 43.5 43.6 43.7 43.8 43.9 44.  44.1 44.2 44.3 44.4 44.5 44.6 44.7 44.8
 44.9 45.  45.1 45.2 45.3 45.4 45.5 45.6 45.7 45.8 45.9 46.  46.1 46.2
 46.3 46.4 46.5 46.6 46.7 46.8 46.9 47.  47.1 47.2 47.3 47.4 47.5 47.6
 47.7 47.8 47.9 48.  48.1 48.2 48.3 48.4 48.5 48.6 48.7 48.8 48.9 49.
 49.1 49.2 49.3 49.4 49.5 49.6 49.7 49.8 49.9 50.  50.1 50.2 50.3 50.4
 50.5 50.6 50.7 50.8 50.9 51.  51.1 51.2 51.3 51.4 51.5 51.6 51.7 51.8
 51.9 52.  52.1 52.2 52.3 52.4 52.5 52.6 52.7 52.8 52.9 53.  53.1 53.2
 53.3 53.4 53.5 53.6 53.7 53.8 53.9 54.  54.1 54.2 54.3 54.4 54.5 54.6
 54.7 54.8 54.9 55.  55.1 55.2 55.3 55.4 55.5 55.6 55.7 55.8 55.9 56.
 56.1 56.2 56.3 56.4 56.5 56.6 56.7 56.8 56.9 57.  57.1 57.2 57.3 57.4
 57.5 57.6 57.7 57.8 57.9 58.  58.1 58.2 58.3 58.4 58.5 58.6 58.7 58.8
 58.9 59.  59.1 59.2 59.3 59.4 59.5 59.6 59.7 59.8 59.9 60.  60.1 60.2
 60.3 60.4 60.5 60.6 60.7 60.8 60.9 61.  61.1 61.2 61.3 61.4 61.5 61.6
 61.7 61.8 61.9 62.  62.1 62.2 62.3 62.4 62.5 62.6 62.7 62.8 62.9 63.
 63.1 63.2 63.3 63.4 63.5 63.6 63.7 63.8 63.9 64.  64.1 64.2 64.3 64.4
 64.5 64.6 64.7 64.8 64.9 65.  65.1 65.2 65.3 65.4 65.5 65.6 65.7 65.8
 65.9 66.  66.1 66.2 66.3 66.4 66.5 66.6 66.7 66.8 66.9 67.  67.1 67.2
 67.3 67.4 67.5 67.6 67.7 67.8 67.9 68.  68.1 68.2 68.3 68.4 68.5 68.6
 68.7 68.8 68.9 69.  69.1 69.2 69.3 69.4 69.5 69.6 69.7 69.8 69.9 70.
 70.1 70.2 70.3 70.4 70.5 70.6 70.7 70.8 70.9 71.  71.1 71.2 71.3 71.4
 71.5 71.6 71.7 71.8 71.9 72.  72.1 72.2 72.3 72.4 72.5 72.6 72.7 72.8
 72.9 73.  73.1 73.2 73.3 73.4 73.5 73.6 73.7 73.8 73.9 74.  74.1 74.2
 74.3 74.4 74.5 74.6 74.7 74.8 74.9 75.  75.1 75.2 75.3 75.4 75.5 75.6
 75.7 75.8 75.9 76.  76.1 76.2 76.3 76.4 76.5 76.6 76.7 76.8 76.9 77.
 77.1 77.2 77.3 77.4 77.5 77.6 77.7 77.8 77.9 78.  78.1 78.2 78.3 78.4
 78.5 78.6 78.7 78.8 78.9 79.  79.1 79.2 79.3 79.4 79.5 79.6 79.7 79.8
 79.9 80.  80.1 80.2 80.3 80.4 80.5 80.6 80.7 80.8 80.9 81.  81.1 81.2
 81.3 81.4 81.5 81.6 81.7 81.8 81.9 82.  82.1 82.2 82.3 82.4 82.5 82.6
 82.7 82.8 82.9 83.  83.1 83.2 83.3 83.4 83.5 83.6 83.7 83.8 83.9 84.
 84.1 84.2 84.3 84.4 84.5 84.6 84.7 84.8 84.9 85.  85.1 85.2 85.3 85.4
 85.5 85.6 85.7 85.8 85.9 86.  86.1 86.2 86.3 86.4 86.5 86.6 86.7 86.8
 86.9 87.  87.1 87.2 87.3 87.4 87.5 87.6 87.7 87.8 87.9 88.  88.1 88.2
 88.3 88.4 88.5 88.6 88.7 88.8 88.9 89.  89.1 89.2 89.3 89.4 89.5 89.6
 89.7 89.8 89.9]
0 90.0
Dataset: RC-49; Resolution: 64x64; num_classes: 49
./evaluation/eval_ckpts/RC49/metrics_64x64/ckpt_AE_epoch_200_seed_2020_CVMode_False.pth
./evaluation/eval_ckpts/RC49/metrics_64x64/ckpt_PreCNNForEvalGANs_ResNet34_class_epoch_200_seed_2020_classify_49_chair_types_CVMode_False.pth
./evaluation/eval_ckpts/RC49/metrics_64x64/ckpt_PreCNNForEvalGANs_ResNet34_regre_epoch_200_seed_2020_CVMode_False.pth

 Start generating fake image-label pairs for evaluation...
100% [##################################################]
 899/899: Got 179800 fake images. Time spent 69.10 sec.
 Fake images shape: (179800, 3, 64, 64)
from evaluation.eval_models.RC49.metrics_64x64 import ResNet34_class_eval, ResNet34_regre_eval, encoder

===================================================================================================

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    âœ“ æ­¥éª¤5å®Œæˆï¼                          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

æ¨¡åž‹ä¿å­˜åœ¨:
  /home/wxc/nuist-lab/CcGAN-AVAR-OOD/output/RC-49_64/oracle_full/

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           ðŸŽ‰ å…¨éƒ¨è®­ç»ƒå®Œæˆï¼                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ä¸‰ä¸ªå¯¹æ¯”å®žéªŒå·²å®Œæˆï¼š

    1. Baseline (åªç”¨0-45åº¦): baseline_id_only/
    2. Simple-Mix (æ··åˆå°‘é‡OOD): simple_mix_50/
    3. Oracle (å…¨éƒ¨0-90åº¦): oracle_full/

å®žéªŒç›®çš„ï¼š

  - Baseline: éªŒè¯OODé—®é¢˜å­˜åœ¨
  - Simple-Mix: æµ‹è¯•ç®€å•æ··åˆæ˜¯å¦è¶³å¤Ÿ
  - Oracle: æ€§èƒ½ä¸Šç•Œå‚è€ƒ

ä¸‹ä¸€æ­¥ï¼šå¯¹æ¯”åˆ†æžç»“æžœ

    1. æŸ¥çœ‹ä¸‰ä¸ªæ¨¡åž‹çš„ results/fake_data/ ç›®å½•
    2. å¯¹æ¯”IDåŒºåŸŸï¼ˆ0-45åº¦ï¼‰å’ŒOODåŒºåŸŸï¼ˆ45-90åº¦ï¼‰çš„ç”Ÿæˆè´¨é‡
    3. åˆ†æžSimple-Mixç›¸æ¯”Baselineçš„æ”¹å–„ç¨‹åº¦
    4. è¯„ä¼°ä¸ŽOracleçš„å·®è· 

(p312) wxc@V100-32Gx4-S2:~/nuist-lab/CcGAN-AVAR-OOD$ ./experiments/eval_all.sh
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘          æ‰¹é‡è¯„ä¼°æ‰€æœ‰å®žéªŒçš„OODæ³›åŒ–æ€§èƒ½                    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… å‘çŽ°: baseline_id_only (30000)
âœ… å‘çŽ°: simple_mix_5 (30000)
âœ… å‘çŽ°: oracle_full (30000)

å°†è¯„ä¼° 3 ä¸ªå®žéªŒ...

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
[1/3] è¯„ä¼°: baseline_id_only
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”


===================================================================================================

 Loaded entire RC-49 dataset: 176400x3x64x64

 The original training set contains 22050 images with labels in [0.0,90.0]; for each label, select no more than 25 images.>>>
 11250 images left and there are 450 unique labels

 The training set's dimension: 11250x3x64x64
 Range of unnormalized labels: (0.1,89.9)
 Range of normalized labels: (0.0011111111111111111,0.9988888888888889)

 The evaluation set's dimension: 44051x3x64x64

 Use rule-of-thumb formula to compute kernel_sigma >>>
 The std of 11250 labels is 0.2887 so the kernel sigma is 0.0474
 Kappa:0.0022

 Loaded entire RC-49 dataset: 176400x3x64x64

 The original training set contains 22050 images with labels in [0.0,90.0]; for each label, select no more than 25 images.>>>
 11250 images left and there are 450 unique labels

 The training set's dimension: 11250x3x64x64
 Range of unnormalized labels: (0.1,89.9)
 Range of normalized labels: (0.0011111111111111111,0.9988888888888889)

 resnet_y2h ckpt already exists

 Loading...

 model mlp_y2h ckpt already exists

 Loading...

 labels vs reconstructed labels
[[0.79       0.7897549 ]
 [0.52111113 0.52155715]
 [0.77       0.76989144]
 [0.7677778  0.76762754]
 [0.15444444 0.15469   ]
 [0.40333334 0.40254524]
 [0.5833333  0.5805443 ]
 [0.48777777 0.4877499 ]
 [0.76555556 0.76535684]
 [0.01       0.01026117]]

 noisy labels vs reconstructed labels
[[0.9653725  0.96731204]
 [0.3371601  0.3377464 ]
 [0.6918372  0.6929012 ]
 [0.28176254 0.28179052]
 [0.16196565 0.16164485]
 [0.6009065  0.59885854]
 [0.87246275 0.87657005]
 [0.10454318 0.10296389]
 [0.67049265 0.67181027]
 [0.         0.00122382]]
 netG size: {'Total': 20301571, 'Trainable': 20301571}
 netD size: {'Total': 20642579, 'Trainable': 20642579}

 Training labels' range is [0.0011111111111111111,0.9988888888888889].
[0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.15 0.15 0.15 0.15
 0.15 0.15 0.15 0.15 0.15 0.15 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25
 0.25 0.25 0.35 0.35 0.35 0.35 0.35 0.35 0.35 0.35 0.35 0.35 0.45 0.45
 0.45 0.45 0.45 0.45 0.45 0.45 0.45 0.45 0.55 0.55 0.55 0.55 0.55 0.55
 0.55 0.55 0.55 0.55 0.65 0.65 0.65 0.65 0.65 0.65 0.65 0.65 0.65 0.65
 0.75 0.75 0.75 0.75 0.75 0.75 0.75 0.75 0.75 0.75 0.85 0.85 0.85 0.85
 0.85 0.85 0.85 0.85 0.85 0.85 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95
 0.95 0.95]


Begin Training:
training complete 

End training; Time elapses: 0.00027424516156315804s. 


 Start sampling fake images from the model >>>

 ====================================================================================
 Start evaluation...

 The evaluation set's dimension: 44051x3x64x64
[ 0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  1.   1.1  1.2  1.3  1.4
  1.5  1.6  1.7  1.8  1.9  2.   2.1  2.2  2.3  2.4  2.5  2.6  2.7  2.8
  2.9  3.   3.1  3.2  3.3  3.4  3.5  3.6  3.7  3.8  3.9  4.   4.1  4.2
  4.3  4.4  4.5  4.6  4.7  4.8  4.9  5.   5.1  5.2  5.3  5.4  5.5  5.6
  5.7  5.8  5.9  6.   6.1  6.2  6.3  6.4  6.5  6.6  6.7  6.8  6.9  7.
  7.1  7.2  7.3  7.4  7.5  7.6  7.7  7.8  7.9  8.   8.1  8.2  8.3  8.4
  8.5  8.6  8.7  8.8  8.9  9.   9.1  9.2  9.3  9.4  9.5  9.6  9.7  9.8
  9.9 10.  10.1 10.2 10.3 10.4 10.5 10.6 10.7 10.8 10.9 11.  11.1 11.2
 11.3 11.4 11.5 11.6 11.7 11.8 11.9 12.  12.1 12.2 12.3 12.4 12.5 12.6
 12.7 12.8 12.9 13.  13.1 13.2 13.3 13.4 13.5 13.6 13.7 13.8 13.9 14.
 14.1 14.2 14.3 14.4 14.5 14.6 14.7 14.8 14.9 15.  15.1 15.2 15.3 15.4
 15.5 15.6 15.7 15.8 15.9 16.  16.1 16.2 16.3 16.4 16.5 16.6 16.7 16.8
 16.9 17.  17.1 17.2 17.3 17.4 17.5 17.6 17.7 17.8 17.9 18.  18.1 18.2
 18.3 18.4 18.5 18.6 18.7 18.8 18.9 19.  19.1 19.2 19.3 19.4 19.5 19.6
 19.7 19.8 19.9 20.  20.1 20.2 20.3 20.4 20.5 20.6 20.7 20.8 20.9 21.
 21.1 21.2 21.3 21.4 21.5 21.6 21.7 21.8 21.9 22.  22.1 22.2 22.3 22.4
 22.5 22.6 22.7 22.8 22.9 23.  23.1 23.2 23.3 23.4 23.5 23.6 23.7 23.8
 23.9 24.  24.1 24.2 24.3 24.4 24.5 24.6 24.7 24.8 24.9 25.  25.1 25.2
 25.3 25.4 25.5 25.6 25.7 25.8 25.9 26.  26.1 26.2 26.3 26.4 26.5 26.6
 26.7 26.8 26.9 27.  27.1 27.2 27.3 27.4 27.5 27.6 27.7 27.8 27.9 28.
 28.1 28.2 28.3 28.4 28.5 28.6 28.7 28.8 28.9 29.  29.1 29.2 29.3 29.4
 29.5 29.6 29.7 29.8 29.9 30.  30.1 30.2 30.3 30.4 30.5 30.6 30.7 30.8
 30.9 31.  31.1 31.2 31.3 31.4 31.5 31.6 31.7 31.8 31.9 32.  32.1 32.2
 32.3 32.4 32.5 32.6 32.7 32.8 32.9 33.  33.1 33.2 33.3 33.4 33.5 33.6
 33.7 33.8 33.9 34.  34.1 34.2 34.3 34.4 34.5 34.6 34.7 34.8 34.9 35.
 35.1 35.2 35.3 35.4 35.5 35.6 35.7 35.8 35.9 36.  36.1 36.2 36.3 36.4
 36.5 36.6 36.7 36.8 36.9 37.  37.1 37.2 37.3 37.4 37.5 37.6 37.7 37.8
 37.9 38.  38.1 38.2 38.3 38.4 38.5 38.6 38.7 38.8 38.9 39.  39.1 39.2
 39.3 39.4 39.5 39.6 39.7 39.8 39.9 40.  40.1 40.2 40.3 40.4 40.5 40.6
 40.7 40.8 40.9 41.  41.1 41.2 41.3 41.4 41.5 41.6 41.7 41.8 41.9 42.
 42.1 42.2 42.3 42.4 42.5 42.6 42.7 42.8 42.9 43.  43.1 43.2 43.3 43.4
 43.5 43.6 43.7 43.8 43.9 44.  44.1 44.2 44.3 44.4 44.5 44.6 44.7 44.8
 44.9 45.  45.1 45.2 45.3 45.4 45.5 45.6 45.7 45.8 45.9 46.  46.1 46.2
 46.3 46.4 46.5 46.6 46.7 46.8 46.9 47.  47.1 47.2 47.3 47.4 47.5 47.6
 47.7 47.8 47.9 48.  48.1 48.2 48.3 48.4 48.5 48.6 48.7 48.8 48.9 49.
 49.1 49.2 49.3 49.4 49.5 49.6 49.7 49.8 49.9 50.  50.1 50.2 50.3 50.4
 50.5 50.6 50.7 50.8 50.9 51.  51.1 51.2 51.3 51.4 51.5 51.6 51.7 51.8
 51.9 52.  52.1 52.2 52.3 52.4 52.5 52.6 52.7 52.8 52.9 53.  53.1 53.2
 53.3 53.4 53.5 53.6 53.7 53.8 53.9 54.  54.1 54.2 54.3 54.4 54.5 54.6
 54.7 54.8 54.9 55.  55.1 55.2 55.3 55.4 55.5 55.6 55.7 55.8 55.9 56.
 56.1 56.2 56.3 56.4 56.5 56.6 56.7 56.8 56.9 57.  57.1 57.2 57.3 57.4
 57.5 57.6 57.7 57.8 57.9 58.  58.1 58.2 58.3 58.4 58.5 58.6 58.7 58.8
 58.9 59.  59.1 59.2 59.3 59.4 59.5 59.6 59.7 59.8 59.9 60.  60.1 60.2
 60.3 60.4 60.5 60.6 60.7 60.8 60.9 61.  61.1 61.2 61.3 61.4 61.5 61.6
 61.7 61.8 61.9 62.  62.1 62.2 62.3 62.4 62.5 62.6 62.7 62.8 62.9 63.
 63.1 63.2 63.3 63.4 63.5 63.6 63.7 63.8 63.9 64.  64.1 64.2 64.3 64.4
 64.5 64.6 64.7 64.8 64.9 65.  65.1 65.2 65.3 65.4 65.5 65.6 65.7 65.8
 65.9 66.  66.1 66.2 66.3 66.4 66.5 66.6 66.7 66.8 66.9 67.  67.1 67.2
 67.3 67.4 67.5 67.6 67.7 67.8 67.9 68.  68.1 68.2 68.3 68.4 68.5 68.6
 68.7 68.8 68.9 69.  69.1 69.2 69.3 69.4 69.5 69.6 69.7 69.8 69.9 70.
 70.1 70.2 70.3 70.4 70.5 70.6 70.7 70.8 70.9 71.  71.1 71.2 71.3 71.4
 71.5 71.6 71.7 71.8 71.9 72.  72.1 72.2 72.3 72.4 72.5 72.6 72.7 72.8
 72.9 73.  73.1 73.2 73.3 73.4 73.5 73.6 73.7 73.8 73.9 74.  74.1 74.2
 74.3 74.4 74.5 74.6 74.7 74.8 74.9 75.  75.1 75.2 75.3 75.4 75.5 75.6
 75.7 75.8 75.9 76.  76.1 76.2 76.3 76.4 76.5 76.6 76.7 76.8 76.9 77.
 77.1 77.2 77.3 77.4 77.5 77.6 77.7 77.8 77.9 78.  78.1 78.2 78.3 78.4
 78.5 78.6 78.7 78.8 78.9 79.  79.1 79.2 79.3 79.4 79.5 79.6 79.7 79.8
 79.9 80.  80.1 80.2 80.3 80.4 80.5 80.6 80.7 80.8 80.9 81.  81.1 81.2
 81.3 81.4 81.5 81.6 81.7 81.8 81.9 82.  82.1 82.2 82.3 82.4 82.5 82.6
 82.7 82.8 82.9 83.  83.1 83.2 83.3 83.4 83.5 83.6 83.7 83.8 83.9 84.
 84.1 84.2 84.3 84.4 84.5 84.6 84.7 84.8 84.9 85.  85.1 85.2 85.3 85.4
 85.5 85.6 85.7 85.8 85.9 86.  86.1 86.2 86.3 86.4 86.5 86.6 86.7 86.8
 86.9 87.  87.1 87.2 87.3 87.4 87.5 87.6 87.7 87.8 87.9 88.  88.1 88.2
 88.3 88.4 88.5 88.6 88.7 88.8 88.9 89.  89.1 89.2 89.3 89.4 89.5 89.6
 89.7 89.8 89.9]
0 90.0
Dataset: RC-49; Resolution: 64x64; num_classes: 49
./evaluation/eval_ckpts/RC49/metrics_64x64/ckpt_AE_epoch_200_seed_2020_CVMode_False.pth
./evaluation/eval_ckpts/RC49/metrics_64x64/ckpt_PreCNNForEvalGANs_ResNet34_class_epoch_200_seed_2020_classify_49_chair_types_CVMode_False.pth
./evaluation/eval_ckpts/RC49/metrics_64x64/ckpt_PreCNNForEvalGANs_ResNet34_regre_epoch_200_seed_2020_CVMode_False.pth

 Start generating fake image-label pairs for evaluation...
100% [##################################################]
 899/899: Got 179800 fake images. Time spent 114.92 sec.
 Fake images shape: (179800, 3, 64, 64)
from evaluation.eval_models.RC49.metrics_64x64 import ResNet34_class_eval, ResNet34_regre_eval, encoder

 Dumping h5 files...
[1/899]: Got 200 fake images for label 0.1 >>>
 [2/899]: Got 200 fake images for label 0.2 >>>
 [3/899]: Got 200 fake images for label 0.3 >>>

...

 [899/899]: Got 200 fake images for label 89.9 >>>
Traceback (most recent call last):
  File "/home/wxc/nuist-lab/CcGAN-AVAR-OOD/main.py", line 314, in <module>
    evaluator.compute_metrics(eval_results_path, PreNetFID, PreNetDiversity, PreNetLS)
  File "/home/wxc/nuist-lab/CcGAN-AVAR-OOD/evaluation/evaluator.py", line 121, in compute_metrics
    checkpoint_PreNet = torch.load(self.fid_net_path, weights_only=True)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/wxc/.conda/envs/p312/lib/python3.12/site-packages/torch/serialization.py", line 1319, in load
    with _open_file_like(f, "rb") as opened_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/wxc/.conda/envs/p312/lib/python3.12/site-packages/torch/serialization.py", line 659, in _open_file_like
    return _open_file(name_or_buffer, mode)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/wxc/.conda/envs/p312/lib/python3.12/site-packages/torch/serialization.py", line 640, in __init__
    super().__init__(open(name, mode))
                     ^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: './evaluation/eval_ckpts/RC49/metrics_64x64/ckpt_AE_epoch_200_seed_2020_CVMode_False.pth'

âœ… baseline_id_only è¯„ä¼°å®Œæˆï¼
   ç»“æžœ: output/RC-49_64/baseline_id_only/eval_*/

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
[2/3] è¯„ä¼°: simple_mix_5
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”


===================================================================================================

 Loaded entire RC-49 dataset: 12150x3x64x64

 The original training set contains 12150 images with labels in [0.0,90.0]; for each label, select no more than 25 images.>>>
 6750 images left and there are 450 unique labels

 The training set's dimension: 6750x3x64x64
 Range of unnormalized labels: (0.1,89.9)
 Range of normalized labels: (0.0011111111111111111,0.9988888888888889)

 The evaluation set's dimension: 12150x3x64x64

 Use rule-of-thumb formula to compute kernel_sigma >>>
 The std of 6750 labels is 0.2357 so the kernel sigma is 0.0428
 Kappa:0.0022

 Loaded entire RC-49 dataset: 12150x3x64x64

 The original training set contains 12150 images with labels in [0.0,90.0]; for each label, select no more than 25 images.>>>
 6750 images left and there are 450 unique labels

 The training set's dimension: 6750x3x64x64
 Range of unnormalized labels: (0.1,89.9)
 Range of normalized labels: (0.0011111111111111111,0.9988888888888889)

 resnet_y2h ckpt already exists

 Loading...

 model mlp_y2h ckpt already exists

 Loading...

 labels vs reconstructed labels
[[0.84555554 0.84740907]
 [0.4077778  0.4070759 ]
 [0.56777775 0.56563437]
 [0.36333334 0.36433592]
 [0.87222224 0.8763129 ]
 [0.86333334 0.8667738 ]
 [0.91888887 0.9257793 ]
 [0.4188889  0.41846147]
 [0.09       0.08744127]
 [0.79888886 0.7986081 ]]

 noisy labels vs reconstructed labels
[[0.7223062  0.72291553]
 [0.5106903  0.5108215 ]
 [0.7399287  0.7394895 ]
 [0.16721189 0.16677207]
 [1.         0.9952517 ]
 [0.56360155 0.5618657 ]
 [1.         0.9952517 ]
 [0.53167486 0.53166276]
 [0.3506049  0.3516533 ]
 [0.7778506  0.7778376 ]]
 netG size: {'Total': 20301571, 'Trainable': 20301571}
 netD size: {'Total': 20642579, 'Trainable': 20642579}

 Training labels' range is [0.0011111111111111111,0.9988888888888889].
[0.03       0.03       0.03       0.03       0.03       0.03
 0.03       0.03       0.03       0.03       0.12111111 0.12111111
 0.12111111 0.12111111 0.12111111 0.12111111 0.12111111 0.12111111
 0.12111111 0.12111111 0.21222222 0.21222222 0.21222222 0.21222222
 0.21222222 0.21222222 0.21222222 0.21222222 0.21222222 0.21222222
 0.30333333 0.30333333 0.30333333 0.30333333 0.30333333 0.30333333
 0.30333333 0.30333333 0.30333333 0.30333333 0.39444444 0.39444444
 0.39444444 0.39444444 0.39444444 0.39444444 0.39444444 0.39444444
 0.39444444 0.39444444 0.48555556 0.48555556 0.48555556 0.48555556
 0.48555556 0.48555556 0.48555556 0.48555556 0.48555556 0.48555556
 0.57666667 0.57666667 0.57666667 0.57666667 0.57666667 0.57666667
 0.57666667 0.57666667 0.57666667 0.57666667 0.66777778 0.66777778
 0.66777778 0.66777778 0.66777778 0.66777778 0.66777778 0.66777778
 0.66777778 0.66777778 0.75888889 0.75888889 0.75888889 0.75888889
 0.75888889 0.75888889 0.75888889 0.75888889 0.75888889 0.75888889
 0.85       0.85       0.85       0.85       0.85       0.85
 0.85       0.85       0.85       0.85      ]


Begin Training:
training complete 

End training; Time elapses: 0.0002717510797083378s. 


 Start sampling fake images from the model >>>

 ====================================================================================
 Start evaluation...

 The evaluation set's dimension: 12150x3x64x64
[ 0.1  0.3  0.5  0.7  0.9  1.1  1.3  1.5  1.7  1.9  2.1  2.3  2.5  2.7
  2.9  3.1  3.3  3.5  3.7  3.9  4.1  4.3  4.5  4.7  4.9  5.1  5.3  5.5
  5.7  5.9  6.1  6.3  6.5  6.7  6.9  7.1  7.3  7.5  7.7  7.9  8.1  8.3
  8.5  8.7  8.9  9.1  9.3  9.5  9.7  9.9 10.1 10.3 10.5 10.7 10.9 11.1
 11.3 11.5 11.7 11.9 12.1 12.3 12.5 12.7 12.9 13.1 13.3 13.5 13.7 13.9
 14.1 14.3 14.5 14.7 14.9 15.1 15.3 15.5 15.7 15.9 16.1 16.3 16.5 16.7
 16.9 17.1 17.3 17.5 17.7 17.9 18.1 18.3 18.5 18.7 18.9 19.1 19.3 19.5
 19.7 19.9 20.1 20.3 20.5 20.7 20.9 21.1 21.3 21.5 21.7 21.9 22.1 22.3
 22.5 22.7 22.9 23.1 23.3 23.5 23.7 23.9 24.1 24.3 24.5 24.7 24.9 25.1
 25.3 25.5 25.7 25.9 26.1 26.3 26.5 26.7 26.9 27.1 27.3 27.5 27.7 27.9
 28.1 28.3 28.5 28.7 28.9 29.1 29.3 29.5 29.7 29.9 30.1 30.3 30.5 30.7
 30.9 31.1 31.3 31.5 31.7 31.9 32.1 32.3 32.5 32.7 32.9 33.1 33.3 33.5
 33.7 33.9 34.1 34.3 34.5 34.7 34.9 35.1 35.3 35.5 35.7 35.9 36.1 36.3
 36.5 36.7 36.9 37.1 37.3 37.5 37.7 37.9 38.1 38.3 38.5 38.7 38.9 39.1
 39.3 39.5 39.7 39.9 40.1 40.3 40.5 40.7 40.9 41.1 41.3 41.5 41.7 41.9
 42.1 42.3 42.5 42.7 42.9 43.1 43.3 43.5 43.7 43.9 44.1 44.3 44.5 44.7
 44.9 45.1 45.3 45.5 45.7 45.9 46.1 46.3 46.5 46.7 46.9 47.1 47.3 47.5
 47.7 47.9 48.1 48.3 48.5 48.7 48.9 49.1 49.3 49.5 49.7 49.9 50.1 50.3
 50.5 50.7 50.9 51.1 51.3 51.5 51.7 51.9 52.1 52.3 52.5 52.7 52.9 53.1
 53.3 53.5 53.7 53.9 54.1 54.3 54.5 54.7 54.9 55.1 55.3 55.5 55.7 55.9
 56.1 56.3 56.5 56.7 56.9 57.1 57.3 57.5 57.7 57.9 58.1 58.3 58.5 58.7
 58.9 59.1 59.3 59.5 59.7 59.9 60.1 60.3 60.5 60.7 60.9 61.1 61.3 61.5
 61.7 61.9 62.1 62.3 62.5 62.7 62.9 63.1 63.3 63.5 63.7 63.9 64.1 64.3
 64.5 64.7 64.9 65.1 65.3 65.5 65.7 65.9 66.1 66.3 66.5 66.7 66.9 67.1
 67.3 67.5 67.7 67.9 68.1 68.3 68.5 68.7 68.9 69.1 69.3 69.5 69.7 69.9
 70.1 70.3 70.5 70.7 70.9 71.1 71.3 71.5 71.7 71.9 72.1 72.3 72.5 72.7
 72.9 73.1 73.3 73.5 73.7 73.9 74.1 74.3 74.5 74.7 74.9 75.1 75.3 75.5
 75.7 75.9 76.1 76.3 76.5 76.7 76.9 77.1 77.3 77.5 77.7 77.9 78.1 78.3
 78.5 78.7 78.9 79.1 79.3 79.5 79.7 79.9 80.1 80.3 80.5 80.7 80.9 81.1
 81.3 81.5 81.7 81.9 82.1 82.3 82.5 82.7 82.9 83.1 83.3 83.5 83.7 83.9
 84.1 84.3 84.5 84.7 84.9 85.1 85.3 85.5 85.7 85.9 86.1 86.3 86.5 86.7
 86.9 87.1 87.3 87.5 87.7 87.9 88.1 88.3 88.5 88.7 88.9 89.1 89.3 89.5
 89.7 89.9]
0 90.0
Dataset: RC-49; Resolution: 64x64; num_classes: 49
./evaluation/eval_ckpts/RC49/metrics_64x64/ckpt_AE_epoch_200_seed_2020_CVMode_False.pth
./evaluation/eval_ckpts/RC49/metrics_64x64/ckpt_PreCNNForEvalGANs_ResNet34_class_epoch_200_seed_2020_classify_49_chair_types_CVMode_False.pth
./evaluation/eval_ckpts/RC49/metrics_64x64/ckpt_PreCNNForEvalGANs_ResNet34_regre_epoch_200_seed_2020_CVMode_False.pth

 Start generating fake image-label pairs for evaluation...
100% [##################################################]
 450/450: Got 90000 fake images. Time spent 57.52 sec.
 Fake images shape: (90000, 3, 64, 64)
from evaluation.eval_models.RC49.metrics_64x64 import ResNet34_class_eval, ResNet34_regre_eval, encoder

 Dumping h5 files...
[1/450]: Got 200 fake images for label 0.1 >>>
 [2/450]: Got 200 fake images for label 0.3 >>>

...

 [449/450]: Got 200 fake images for label 89.7 >>>
 [450/450]: Got 200 fake images for label 89.9 >>>
Traceback (most recent call last):
  File "/home/wxc/nuist-lab/CcGAN-AVAR-OOD/main.py", line 314, in <module>
    evaluator.compute_metrics(eval_results_path, PreNetFID, PreNetDiversity, PreNetLS)
  File "/home/wxc/nuist-lab/CcGAN-AVAR-OOD/evaluation/evaluator.py", line 121, in compute_metrics
    checkpoint_PreNet = torch.load(self.fid_net_path, weights_only=True)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/wxc/.conda/envs/p312/lib/python3.12/site-packages/torch/serialization.py", line 1319, in load
    with _open_file_like(f, "rb") as opened_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/wxc/.conda/envs/p312/lib/python3.12/site-packages/torch/serialization.py", line 659, in _open_file_like
    return _open_file(name_or_buffer, mode)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/wxc/.conda/envs/p312/lib/python3.12/site-packages/torch/serialization.py", line 640, in __init__
    super().__init__(open(name, mode))
                     ^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: './evaluation/eval_ckpts/RC49/metrics_64x64/ckpt_AE_epoch_200_seed_2020_CVMode_False.pth'

âœ… simple_mix_5 è¯„ä¼°å®Œæˆï¼
   ç»“æžœ: output/RC-49_64/simple_mix_5/eval_*/

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
[3/3] è¯„ä¼°: oracle_full
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”


===================================================================================================

 Loaded entire RC-49 dataset: 176400x3x64x64

 The original training set contains 22050 images with labels in [0.0,90.0]; for each label, select no more than 25 images.>>>
 11250 images left and there are 450 unique labels

 The training set's dimension: 11250x3x64x64
 Range of unnormalized labels: (0.1,89.9)
 Range of normalized labels: (0.0011111111111111111,0.9988888888888889)

 The evaluation set's dimension: 44051x3x64x64

 Use rule-of-thumb formula to compute kernel_sigma >>>
 The std of 11250 labels is 0.2887 so the kernel sigma is 0.0474
 Kappa:0.0022

 Loaded entire RC-49 dataset: 176400x3x64x64

 The original training set contains 22050 images with labels in [0.0,90.0]; for each label, select no more than 25 images.>>>
 11250 images left and there are 450 unique labels

 The training set's dimension: 11250x3x64x64
 Range of unnormalized labels: (0.1,89.9)
 Range of normalized labels: (0.0011111111111111111,0.9988888888888889)

 resnet_y2h ckpt already exists

 Loading...

 model mlp_y2h ckpt already exists

 Loading...

 labels vs reconstructed labels
[[0.79       0.7897549 ]
 [0.52111113 0.52155715]
 [0.77       0.76989144]
 [0.7677778  0.76762754]
 [0.15444444 0.15469   ]
 [0.40333334 0.40254524]
 [0.5833333  0.5805443 ]
 [0.48777777 0.4877499 ]
 [0.76555556 0.76535684]
 [0.01       0.01026117]]

 noisy labels vs reconstructed labels
[[0.9653725  0.96731204]
 [0.3371601  0.3377464 ]
 [0.6918372  0.6929012 ]
 [0.28176254 0.28179052]
 [0.16196565 0.16164485]
 [0.6009065  0.59885854]
 [0.87246275 0.87657005]
 [0.10454318 0.10296389]
 [0.67049265 0.67181027]
 [0.         0.00122382]]
 netG size: {'Total': 20301571, 'Trainable': 20301571}
 netD size: {'Total': 20642579, 'Trainable': 20642579}

 Training labels' range is [0.0011111111111111111,0.9988888888888889].
[0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.15 0.15 0.15 0.15
 0.15 0.15 0.15 0.15 0.15 0.15 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25
 0.25 0.25 0.35 0.35 0.35 0.35 0.35 0.35 0.35 0.35 0.35 0.35 0.45 0.45
 0.45 0.45 0.45 0.45 0.45 0.45 0.45 0.45 0.55 0.55 0.55 0.55 0.55 0.55
 0.55 0.55 0.55 0.55 0.65 0.65 0.65 0.65 0.65 0.65 0.65 0.65 0.65 0.65
 0.75 0.75 0.75 0.75 0.75 0.75 0.75 0.75 0.75 0.75 0.85 0.85 0.85 0.85
 0.85 0.85 0.85 0.85 0.85 0.85 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95
 0.95 0.95]


Begin Training:
training complete 

End training; Time elapses: 0.0002691859845072031s. 


 Start sampling fake images from the model >>>

 ====================================================================================
 Start evaluation...

 The evaluation set's dimension: 44051x3x64x64
[ 0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  1.   1.1  1.2  1.3  1.4
  1.5  1.6  1.7  1.8  1.9  2.   2.1  2.2  2.3  2.4  2.5  2.6  2.7  2.8
  2.9  3.   3.1  3.2  3.3  3.4  3.5  3.6  3.7  3.8  3.9  4.   4.1  4.2
  4.3  4.4  4.5  4.6  4.7  4.8  4.9  5.   5.1  5.2  5.3  5.4  5.5  5.6
  5.7  5.8  5.9  6.   6.1  6.2  6.3  6.4  6.5  6.6  6.7  6.8  6.9  7.
  7.1  7.2  7.3  7.4  7.5  7.6  7.7  7.8  7.9  8.   8.1  8.2  8.3  8.4
  8.5  8.6  8.7  8.8  8.9  9.   9.1  9.2  9.3  9.4  9.5  9.6  9.7  9.8
  9.9 10.  10.1 10.2 10.3 10.4 10.5 10.6 10.7 10.8 10.9 11.  11.1 11.2
 11.3 11.4 11.5 11.6 11.7 11.8 11.9 12.  12.1 12.2 12.3 12.4 12.5 12.6
 12.7 12.8 12.9 13.  13.1 13.2 13.3 13.4 13.5 13.6 13.7 13.8 13.9 14.
 14.1 14.2 14.3 14.4 14.5 14.6 14.7 14.8 14.9 15.  15.1 15.2 15.3 15.4
 15.5 15.6 15.7 15.8 15.9 16.  16.1 16.2 16.3 16.4 16.5 16.6 16.7 16.8
 16.9 17.  17.1 17.2 17.3 17.4 17.5 17.6 17.7 17.8 17.9 18.  18.1 18.2
 18.3 18.4 18.5 18.6 18.7 18.8 18.9 19.  19.1 19.2 19.3 19.4 19.5 19.6
 19.7 19.8 19.9 20.  20.1 20.2 20.3 20.4 20.5 20.6 20.7 20.8 20.9 21.
 21.1 21.2 21.3 21.4 21.5 21.6 21.7 21.8 21.9 22.  22.1 22.2 22.3 22.4
 22.5 22.6 22.7 22.8 22.9 23.  23.1 23.2 23.3 23.4 23.5 23.6 23.7 23.8
 23.9 24.  24.1 24.2 24.3 24.4 24.5 24.6 24.7 24.8 24.9 25.  25.1 25.2
 25.3 25.4 25.5 25.6 25.7 25.8 25.9 26.  26.1 26.2 26.3 26.4 26.5 26.6
 26.7 26.8 26.9 27.  27.1 27.2 27.3 27.4 27.5 27.6 27.7 27.8 27.9 28.
 28.1 28.2 28.3 28.4 28.5 28.6 28.7 28.8 28.9 29.  29.1 29.2 29.3 29.4
 29.5 29.6 29.7 29.8 29.9 30.  30.1 30.2 30.3 30.4 30.5 30.6 30.7 30.8
 30.9 31.  31.1 31.2 31.3 31.4 31.5 31.6 31.7 31.8 31.9 32.  32.1 32.2
 32.3 32.4 32.5 32.6 32.7 32.8 32.9 33.  33.1 33.2 33.3 33.4 33.5 33.6
 33.7 33.8 33.9 34.  34.1 34.2 34.3 34.4 34.5 34.6 34.7 34.8 34.9 35.
 35.1 35.2 35.3 35.4 35.5 35.6 35.7 35.8 35.9 36.  36.1 36.2 36.3 36.4
 36.5 36.6 36.7 36.8 36.9 37.  37.1 37.2 37.3 37.4 37.5 37.6 37.7 37.8
 37.9 38.  38.1 38.2 38.3 38.4 38.5 38.6 38.7 38.8 38.9 39.  39.1 39.2
 39.3 39.4 39.5 39.6 39.7 39.8 39.9 40.  40.1 40.2 40.3 40.4 40.5 40.6
 40.7 40.8 40.9 41.  41.1 41.2 41.3 41.4 41.5 41.6 41.7 41.8 41.9 42.
 42.1 42.2 42.3 42.4 42.5 42.6 42.7 42.8 42.9 43.  43.1 43.2 43.3 43.4
 43.5 43.6 43.7 43.8 43.9 44.  44.1 44.2 44.3 44.4 44.5 44.6 44.7 44.8
 44.9 45.  45.1 45.2 45.3 45.4 45.5 45.6 45.7 45.8 45.9 46.  46.1 46.2
 46.3 46.4 46.5 46.6 46.7 46.8 46.9 47.  47.1 47.2 47.3 47.4 47.5 47.6
 47.7 47.8 47.9 48.  48.1 48.2 48.3 48.4 48.5 48.6 48.7 48.8 48.9 49.
 49.1 49.2 49.3 49.4 49.5 49.6 49.7 49.8 49.9 50.  50.1 50.2 50.3 50.4
 50.5 50.6 50.7 50.8 50.9 51.  51.1 51.2 51.3 51.4 51.5 51.6 51.7 51.8
 51.9 52.  52.1 52.2 52.3 52.4 52.5 52.6 52.7 52.8 52.9 53.  53.1 53.2
 53.3 53.4 53.5 53.6 53.7 53.8 53.9 54.  54.1 54.2 54.3 54.4 54.5 54.6
 54.7 54.8 54.9 55.  55.1 55.2 55.3 55.4 55.5 55.6 55.7 55.8 55.9 56.
 56.1 56.2 56.3 56.4 56.5 56.6 56.7 56.8 56.9 57.  57.1 57.2 57.3 57.4
 57.5 57.6 57.7 57.8 57.9 58.  58.1 58.2 58.3 58.4 58.5 58.6 58.7 58.8
 58.9 59.  59.1 59.2 59.3 59.4 59.5 59.6 59.7 59.8 59.9 60.  60.1 60.2
 60.3 60.4 60.5 60.6 60.7 60.8 60.9 61.  61.1 61.2 61.3 61.4 61.5 61.6
 61.7 61.8 61.9 62.  62.1 62.2 62.3 62.4 62.5 62.6 62.7 62.8 62.9 63.
 63.1 63.2 63.3 63.4 63.5 63.6 63.7 63.8 63.9 64.  64.1 64.2 64.3 64.4
 64.5 64.6 64.7 64.8 64.9 65.  65.1 65.2 65.3 65.4 65.5 65.6 65.7 65.8
 65.9 66.  66.1 66.2 66.3 66.4 66.5 66.6 66.7 66.8 66.9 67.  67.1 67.2
 67.3 67.4 67.5 67.6 67.7 67.8 67.9 68.  68.1 68.2 68.3 68.4 68.5 68.6
 68.7 68.8 68.9 69.  69.1 69.2 69.3 69.4 69.5 69.6 69.7 69.8 69.9 70.
 70.1 70.2 70.3 70.4 70.5 70.6 70.7 70.8 70.9 71.  71.1 71.2 71.3 71.4
 71.5 71.6 71.7 71.8 71.9 72.  72.1 72.2 72.3 72.4 72.5 72.6 72.7 72.8
 72.9 73.  73.1 73.2 73.3 73.4 73.5 73.6 73.7 73.8 73.9 74.  74.1 74.2
 74.3 74.4 74.5 74.6 74.7 74.8 74.9 75.  75.1 75.2 75.3 75.4 75.5 75.6
 75.7 75.8 75.9 76.  76.1 76.2 76.3 76.4 76.5 76.6 76.7 76.8 76.9 77.
 77.1 77.2 77.3 77.4 77.5 77.6 77.7 77.8 77.9 78.  78.1 78.2 78.3 78.4
 78.5 78.6 78.7 78.8 78.9 79.  79.1 79.2 79.3 79.4 79.5 79.6 79.7 79.8
 79.9 80.  80.1 80.2 80.3 80.4 80.5 80.6 80.7 80.8 80.9 81.  81.1 81.2
 81.3 81.4 81.5 81.6 81.7 81.8 81.9 82.  82.1 82.2 82.3 82.4 82.5 82.6
 82.7 82.8 82.9 83.  83.1 83.2 83.3 83.4 83.5 83.6 83.7 83.8 83.9 84.
 84.1 84.2 84.3 84.4 84.5 84.6 84.7 84.8 84.9 85.  85.1 85.2 85.3 85.4
 85.5 85.6 85.7 85.8 85.9 86.  86.1 86.2 86.3 86.4 86.5 86.6 86.7 86.8
 86.9 87.  87.1 87.2 87.3 87.4 87.5 87.6 87.7 87.8 87.9 88.  88.1 88.2
 88.3 88.4 88.5 88.6 88.7 88.8 88.9 89.  89.1 89.2 89.3 89.4 89.5 89.6
 89.7 89.8 89.9]
0 90.0
Dataset: RC-49; Resolution: 64x64; num_classes: 49
./evaluation/eval_ckpts/RC49/metrics_64x64/ckpt_AE_epoch_200_seed_2020_CVMode_False.pth
./evaluation/eval_ckpts/RC49/metrics_64x64/ckpt_PreCNNForEvalGANs_ResNet34_class_epoch_200_seed_2020_classify_49_chair_types_CVMode_False.pth
./evaluation/eval_ckpts/RC49/metrics_64x64/ckpt_PreCNNForEvalGANs_ResNet34_regre_epoch_200_seed_2020_CVMode_False.pth

 Start generating fake image-label pairs for evaluation...
100% [##################################################]
 899/899: Got 179800 fake images. Time spent 114.80 sec.
 Fake images shape: (179800, 3, 64, 64)
from evaluation.eval_models.RC49.metrics_64x64 import ResNet34_class_eval, ResNet34_regre_eval, encoder

 Dumping h5 files...
[1/899]: Got 200 fake images for label 0.1 >>>
 [2/899]: Got 200 fake images for label 0.2 >>>

...

 [898/899]: Got 200 fake images for label 89.8 >>>
 [899/899]: Got 200 fake images for label 89.9 >>>
Traceback (most recent call last):
  File "/home/wxc/nuist-lab/CcGAN-AVAR-OOD/main.py", line 314, in <module>
    evaluator.compute_metrics(eval_results_path, PreNetFID, PreNetDiversity, PreNetLS)
  File "/home/wxc/nuist-lab/CcGAN-AVAR-OOD/evaluation/evaluator.py", line 121, in compute_metrics
    checkpoint_PreNet = torch.load(self.fid_net_path, weights_only=True)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/wxc/.conda/envs/p312/lib/python3.12/site-packages/torch/serialization.py", line 1319, in load
    with _open_file_like(f, "rb") as opened_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/wxc/.conda/envs/p312/lib/python3.12/site-packages/torch/serialization.py", line 659, in _open_file_like
    return _open_file(name_or_buffer, mode)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/wxc/.conda/envs/p312/lib/python3.12/site-packages/torch/serialization.py", line 640, in __init__
    super().__init__(open(name, mode))
                     ^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: './evaluation/eval_ckpts/RC49/metrics_64x64/ckpt_AE_epoch_200_seed_2020_CVMode_False.pth'

âœ… oracle_full è¯„ä¼°å®Œæˆï¼
   ç»“æžœ: output/RC-49_64/oracle_full/eval_*/


â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                 âœ“ æ‰€æœ‰è¯„ä¼°å®Œæˆï¼                          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ðŸ“Š æŸ¥çœ‹è¯„ä¼°ç»“æžœï¼š

ã€baseline_id_onlyã€‘
  è¯„ä¼°æŠ¥å‘Š: output/RC-49_64/baseline_id_only/eval_2025-11-08_21-32-31/eval_results.txt

ã€simple_mix_5ã€‘
  è¯„ä¼°æŠ¥å‘Š: output/RC-49_64/simple_mix_5/eval_2025-11-08_21-35-28/eval_results.txt

ã€oracle_fullã€‘
  è¯„ä¼°æŠ¥å‘Š: output/RC-49_64/oracle_full/eval_2025-11-08_21-41-49/eval_results.txt

ðŸ’¡ æç¤ºï¼š

  - å®Œæ•´æŠ¥å‘Š: cat output/RC-49_64/*/eval_*/eval_results.txt
  - ç”Ÿæˆå›¾ç‰‡: ls output/RC-49_64/*/results/fake_data/h5/